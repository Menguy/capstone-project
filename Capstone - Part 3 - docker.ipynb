{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask & Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re as re\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import joblib\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "MODEL_DIR = 'models'\n",
    "DATA_DIR = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = 'C:\\\\Users\\\\ERICMenguy\\\\Documents\\\\AIAcademy\\\\Part B\\\\AI in Production\\\\ai-workflow-capstone-master\\\\'\n",
    "os.chdir(current_path)\n",
    "if not os.path.exists(\"models\") :\n",
    "    os.mkdir(\"models\")\n",
    "MODEL_DIR=os.path.join(current_path,\"models\")\n",
    "DATA_DIR=os.path.join(current_path,\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing pipeline\n",
    "#### There is not really any preprocessing task, except differencing\n",
    "\n",
    "def load_invoices_data():\n",
    "    column_names = [\"country\",\"customer_id\",\"invoice\",\"price\",\"stream_id\",\"times_viewed\",\"year\",\"month\",\"day\"]\n",
    "    df = pd.DataFrame(columns = column_names) \n",
    "    list_files = os.listdir(DATA_DIR)\n",
    "    \n",
    "    for file in list_files:\n",
    "        with open(os.path.join(DATA_DIR,file)) as f:\n",
    "            data = json.load(f)\n",
    "            df_new = pd.DataFrame(data)\n",
    "            actual_column_names=list(df_new.columns.values)\n",
    "            for k in range(len(actual_column_names)):\n",
    "                df_new.rename(columns={actual_column_names[k]: column_names[k]}, inplace=True)       \n",
    "            df_new.head()\n",
    "            df = df.append(df_new,ignore_index = True)\n",
    "            \n",
    "    # Post preparation\n",
    "    def find_number(text):\n",
    "        num = re.findall(r'[0-9]+',text)\n",
    "        return \" \".join(num)\n",
    "        \n",
    "    df['invoice']=df['invoice'].apply(lambda x: find_number(x))   \n",
    "    df['times_viewed'] = pd.to_numeric(df['times_viewed'], errors='coerce')\n",
    "    df['month'] = pd.to_numeric(df['month'], errors='coerce')\n",
    "    df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "    df['day'] = pd.to_numeric(df['day'], errors='coerce')\n",
    "    \n",
    "    df.loc[df['price'] < 0] = 0\n",
    "    df = df.loc[df['year'] > 0]\n",
    "    \n",
    "    \n",
    "    # monthly aggregation\n",
    "        ## Prepare data to get the number of purchase. A purchases are identified by invoice id\n",
    "    df1=pd.pivot_table(df, index=['country','invoice','year','month','day'], \n",
    "                                 values=['price','times_viewed'],\n",
    "                                 aggfunc='sum').round(1)\n",
    "    df1['purchase'] = 1\n",
    "         ## Aggregation\n",
    "    df2 = pd.pivot_table(df1, index=['year','month'], #'country',\n",
    "                                            values=['price','times_viewed','purchase'],\n",
    "                                            aggfunc='sum').round(2)\n",
    "    \n",
    "    # Create time series\n",
    "    df2.reset_index(inplace = True)\n",
    "    df2['day'] = 1\n",
    "    df2['date'] = pd.to_datetime(df2[['year', 'month','day']])\n",
    "    # Convert to time series\n",
    "    ts= df2.set_index('date')\n",
    "    \n",
    "    ts.drop(columns=['year','month','day'],inplace = True)\n",
    "\n",
    "    #return\n",
    "    del df1,df2\n",
    "    return(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist a machine learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data (you may need to adjust the location of the data to match your system)\n",
    "X = load_invoices_data()\n",
    "\n",
    "### focus only on price\n",
    "X = X[['price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aic value : 206.00039008233236\n",
      "price                mean        mean_se  mean_ci_lower  mean_ci_upper\n",
      "2019-08-01  192886.235867   93527.682511    9575.346588  376197.125145\n",
      "2019-09-01  202789.107543  132268.117064  -56451.638205  462029.853291\n",
      "2019-10-01  217184.051976  161994.698023 -100319.721835  534687.825787\n",
      "2019-11-01  254691.015519  187055.365016 -111930.763028  621312.794066\n",
      "2019-12-01  357755.247842  209132.529577  -52136.978125  767647.473809\n",
      "2020-01-01  353706.521672  229091.947203  -95305.443994  802718.487337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\ERICMenguy\\\\Documents\\\\AIAcademy\\\\Part B\\\\AI in Production\\\\ai-workflow-capstone-master\\\\models\\\\capstone.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train and check model performance (assumes you have already grid-searched to tune model)\n",
    "#### param with minimum AIC value are : [((0, 1, 0), (1, 1, 0, 12))]\n",
    "\n",
    "model = sm.tsa.statespace.SARIMAX(X,order=(0, 1, 0),seasonal_order=(1, 1, 0, 12))\n",
    "result = model.fit()\n",
    "print('aic value :', result.aic)\n",
    "\n",
    "forecast = result.get_forecast(steps=6)\n",
    "print(forecast.summary_frame())\n",
    "\n",
    "## Save model\n",
    "saved_model = 'capstone.joblib'\n",
    "joblib.dump(result,os.path.join(MODEL_DIR,saved_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price                mean        mean_se  mean_ci_lower  mean_ci_upper\n",
      "2019-08-01  192886.235867   93527.682511    9575.346588  376197.125145\n",
      "2019-09-01  202789.107543  132268.117064  -56451.638205  462029.853291\n",
      "2019-10-01  217184.051976  161994.698023 -100319.721835  534687.825787\n",
      "2019-11-01  254691.015519  187055.365016 -111930.763028  621312.794066\n",
      "2019-12-01  357755.247842  209132.529577  -52136.978125  767647.473809\n",
      "2020-01-01  353706.521672  229091.947203  -95305.443994  802718.487337\n"
     ]
    }
   ],
   "source": [
    "# test reload model before updating app.py\n",
    "\n",
    "saved_model = 'capstone.joblib'\n",
    "loaded_model = joblib.load(os.path.join(MODEL_DIR, saved_model))\n",
    "forecast = loaded_model.get_forecast(6)\n",
    "print(forecast.summary_frame())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a simple flask app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "from flask import Flask, jsonify, request\n",
    "import joblib\n",
    "import socket\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "MODEL_DIR = 'models'\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "#def hello():\n",
    "#    html = \"<h3>Capstone {name}!</h3>\" \\\n",
    "#           \"<b>Hostname:</b> {hostname}<br/>\"\n",
    "#    return html.format(name=os.getenv(\"NAME\", \"world\"), hostname=socket.gethostname())\n",
    "\n",
    "@app.route('/get_forecast', methods=['GET','POST'])\n",
    "\n",
    "def get_forecast():   \n",
    "    ## input checking\n",
    "    if not request.json:\n",
    "        print(\"ERROR: API (predict): did not receive request data\")\n",
    "        return jsonify([])\n",
    "    \n",
    "    query = request.json\n",
    "    query_init = query\n",
    "    query = pd.DataFrame.from_dict(query,orient = 'index')\n",
    "\n",
    "    if len(query.shape) == 1:\n",
    "         query = query.reshape(1, -1)\n",
    "\n",
    "    forecast = model.get_forecast(query[0][0])\n",
    "    \n",
    "    result = forecast.summary_frame()\n",
    "    result.drop(columns=['mean_se','mean_ci_lower','mean_ci_upper'],inplace=True)\n",
    "    result.rename(columns={\"mean\": \"forecast\"},inplace=True)\n",
    "    result.index = result.index.set_names(['date'])\n",
    "    result = result.reset_index()\n",
    "    result['date'] = result['date'].astype(str)\n",
    "\n",
    "    dict=result.to_dict('records')\n",
    "    \n",
    "    return(jsonify(dict))\n",
    "\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    saved_model = 'capstone.joblib'\n",
    "    model = joblib.load(os.path.join(MODEL_DIR, saved_model))\n",
    "    app.run(host='127.0.0.1', port=5000,debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the flask app\n",
    "\n",
    "Move into your `docker-tutorial` directory and start the app \n",
    "\n",
    "\n",
    "```bash\n",
    "$ python app.py\n",
    "```\n",
    "\n",
    "Then go to [http://127.0.0.1:5000/](http://127.0.0.1:5000/)\n",
    "\n",
    "Stop the server.  We will relaunch it in a few moments from within Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the DockerFile\n",
    "\n",
    "Before we build the DockerFile first we need to create a requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "cython\n",
    "numpy\n",
    "flask\n",
    "pandas\n",
    "scikit-learn\n",
    "statsmodels.api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "# Use an official Python runtime as a parent image\n",
    "FROM python:3.7.3-stretch\n",
    "\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "python3-dev \\\n",
    "build-essential    \n",
    "        \n",
    "# Set the working directory to /app\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy the current directory contents into the container at /app\n",
    "ADD . /app\n",
    "\n",
    "# Install any needed packages specified in requirements.txt\n",
    "RUN pip install --upgrade pip\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Make port 80 available to the world outside this container\n",
    "EXPOSE 80\n",
    "\n",
    "# Define environment variable\n",
    "ENV NAME World\n",
    "\n",
    "# Run app.py when the container launches\n",
    "CMD [\"python\", \"app.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the running app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define horizon\n",
    "query = {\n",
    "    'steps' : '2019-11-01'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2019-08-01', 'forecast': 192886.23586675752}, {'date': '2019-09-01', 'forecast': 202789.10754276463}, {'date': '2019-10-01', 'forecast': 217184.0519760289}, {'date': '2019-11-01', 'forecast': 254691.01551877992}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from ast import literal_eval\n",
    "\n",
    "## data needs to be in dict format for JSON\n",
    "\n",
    "## test the Flask API\n",
    "port = 5000\n",
    "r = requests.post('http://127.0.0.1:{}/get_forecast'.format(port),json=query)\n",
    "\n",
    "## test the Docker API\n",
    "#port = 5000\n",
    "#r = requests.post('http://127.0.0.1:{}/get_forecast'.format(port),json=query)\n",
    "\n",
    "response = literal_eval(r.text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
